{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_png(directory, label, target):\n",
    "    for i, image in enumerate(os.listdir(directory)):\n",
    "        f = os.path.join(directory, image)\n",
    "        if os.path.isfile(f):\n",
    "            image = Image.open(f)\n",
    "            image.save(f'data/{i}{label}.{target}')\n",
    "            \n",
    "    os.system('rmdir /S /Q \"{}\"'.format(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    DO NOT RUN\n",
    "\"\"\"\n",
    "\n",
    "directory_1 = 'data/cancer'\n",
    "directory_2 = 'data/non-cancer'\n",
    "target = 'png'\n",
    "\n",
    "convert_png(directory_1, 1, target)\n",
    "convert_png(directory_2, 0, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    \"\"\"\n",
    "    A class for preprocessing images.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): The directory containing the images.\n",
    "        target_size (tuple): The target size of the images after resizing.\n",
    "        normalize_range (tuple): The range to normalize the pixel values to.\n",
    "\n",
    "    Attributes:\n",
    "        image_dir (str): The directory containing the images.\n",
    "        target_size (tuple): The target size of the images after resizing.\n",
    "        normalize_range (tuple): The range to normalize the pixel values to.\n",
    "        image_hashes (dict): A dictionary to store the image hashes.\n",
    "\n",
    "    Methods:\n",
    "        hash_image(image): Computes the hash value of an image.\n",
    "        check_duplicates(): Checks for duplicate images and performs augmentation if necessary.\n",
    "        augment_image(image): Applies a random augmentation to an image.\n",
    "        resize_image(image): Resizes an image to the target size.\n",
    "        normalize_image(image): Normalizes the pixel values of an image.\n",
    "        convert_to_tensor(image): Converts an image to a tensor.\n",
    "        preprocess_image(): Preprocesses the images in the image directory.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, target_size, normalize_range):\n",
    "            \"\"\"\n",
    "            Initializes a SmileSavior object.\n",
    "\n",
    "            Args:\n",
    "                image_dir (str): The directory path where the images are stored.\n",
    "                target_size (tuple): The desired size of the images after resizing.\n",
    "                normalize_range (bool): Flag indicating whether to normalize the pixel values of the images.\n",
    "\n",
    "            Attributes:\n",
    "                image_dir (str): The directory path where the images are stored.\n",
    "                target_size (tuple): The desired size of the images after resizing.\n",
    "                normalize_range (bool): Flag indicating whether to normalize the pixel values of the images.\n",
    "                image_hashes (dict): A dictionary to store the hashes of the images.\n",
    "\n",
    "            \"\"\"\n",
    "            self.image_dir = image_dir\n",
    "            self.target_size = target_size\n",
    "            self.normalize_range = normalize_range\n",
    "            self.image_hashes = {}\n",
    "\n",
    "    def hash_image(self, image):\n",
    "        \"\"\"\n",
    "        Calculates the MD5 hash of the given image.\n",
    "\n",
    "        Parameters:\n",
    "        image (numpy.ndarray): The image to be hashed.\n",
    "\n",
    "        Returns:\n",
    "        str: The MD5 hash of the image.\n",
    "        \"\"\"\n",
    "        return hashlib.md5(image.tobytes()).hexdigest()\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        \"\"\"\n",
    "        Check for duplicate images in the specified image directory and perform image augmentation if duplicates are found.\n",
    "\n",
    "        This method iterates over all the images in the specified image directory and checks if each image has a duplicate.\n",
    "        If a duplicate is found, the image is augmented and saved, replacing the original image. If no duplicate is found,\n",
    "        the image is added to the list of image hashes for future comparison.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        images = glob.glob(os.path.join(self.image_dir, '*'))\n",
    "        for image_path in images:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_hash = self.hash_image(image)\n",
    "            \n",
    "            if image_hash in self.image_hashes:\n",
    "                image = self.augment_image(image)\n",
    "                image.save(image_path)\n",
    "            else:\n",
    "                self.image_hashes[image_hash] = image_path\n",
    "\n",
    "    def augment_image(self, image):\n",
    "            \"\"\"\n",
    "            Apply a random augmentation to the given image.\n",
    "\n",
    "            Parameters:\n",
    "            image (PIL.Image.Image): The input image to be augmented.\n",
    "\n",
    "            Returns:\n",
    "            PIL.Image.Image: The augmented image.\n",
    "            \"\"\"\n",
    "            augmentations = [\n",
    "                ImageOps.mirror,\n",
    "                ImageOps.flip,\n",
    "                lambda img: img.rotate(90)\n",
    "            ]\n",
    "            augmentation = np.random.choice(augmentations)\n",
    "            return augmentation(image)\n",
    "    \n",
    "    def resize_image(self, image):\n",
    "        \"\"\"\n",
    "        Resizes the given image to the target size.\n",
    "\n",
    "        Parameters:\n",
    "        - image: The image to be resized.\n",
    "\n",
    "        Returns:\n",
    "        - The resized image.\n",
    "        \"\"\"\n",
    "        return image.resize(self.target_size)\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        \"\"\"\n",
    "        Normalize the given image.\n",
    "\n",
    "        Args:\n",
    "            image (PIL.Image.Image): The input image to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            PIL.Image.Image: The normalized image.\n",
    "\n",
    "        \"\"\"\n",
    "        image_array = np.array(image).astype(np.float32)\n",
    "        image_array /= 255.0\n",
    "        if self.normalize_range == (-1, 1):\n",
    "            image_array = image_array * 2 - 1\n",
    "        return Image.fromarray((image_array * 255).astype(np.uint8))\n",
    "    \n",
    "    def convert_to_tensor(self, image):\n",
    "        \"\"\"\n",
    "        Converts an image to a PyTorch tensor.\n",
    "\n",
    "        Args:\n",
    "            image (PIL.Image.Image): The input image.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The converted tensor representation of the image.\n",
    "        \"\"\"\n",
    "        transform = transforms.ToTensor()\n",
    "        return transform(image)\n",
    "    \n",
    "    def preprocess_image(self):\n",
    "            \"\"\"\n",
    "            Preprocesses the images in the specified directory.\n",
    "\n",
    "            Returns:\n",
    "            processed_images (list): A list of processed images.\n",
    "            \"\"\"\n",
    "            self.check_duplicates()\n",
    "            images = glob.glob(os.path.join(self.image_dir, '*'))\n",
    "            if not images:\n",
    "                print(\"No images found in the directory.\")\n",
    "\n",
    "            processed_images = []\n",
    "            labels = []\n",
    "            for image_path in images:\n",
    "                print(f\"Processing image: {image_path}\")\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image = self.resize_image(image)\n",
    "                print(f\"Resized image: {image.size}\")\n",
    "                image = self.normalize_image(image)\n",
    "                print(f\"Normalized image: {np.array(image).shape}\")\n",
    "                image = self.convert_to_tensor(image)\n",
    "                print(f\"Converted to tensor: {image.shape}\")\n",
    "                processed_images.append(image)\n",
    "                \n",
    "                target = image_path.split('.')[0][-1]\n",
    "                labels.append(target)\n",
    "                \n",
    "            return processed_images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: data\\00.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\01.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\10.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\100.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\101.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\11.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\110.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\111.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\120.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\121.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\130.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\131.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\140.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\141.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\150.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\151.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\160.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\161.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\170.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\171.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\180.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\181.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\190.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\191.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\20.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\200.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\201.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\21.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\210.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\211.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\220.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\221.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\230.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\231.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\240.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\241.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\250.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\251.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\260.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\261.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\270.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\271.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\280.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\281.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\290.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\291.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\30.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\300.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\301.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\31.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\310.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\311.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\320.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\321.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\330.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\331.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\340.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\341.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\350.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\351.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\360.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\361.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\370.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\371.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\380.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\381.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\390.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\391.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\40.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\400.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\401.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\41.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\410.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\411.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\420.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\421.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\430.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\431.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\441.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\451.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\461.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\471.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\481.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\491.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\50.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\501.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\51.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\511.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\521.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\531.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\541.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\551.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\561.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\571.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\581.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\591.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\60.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\601.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\61.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\611.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\621.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\631.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\641.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\651.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\661.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\671.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\681.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\691.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\70.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\701.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\71.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\711.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\721.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\731.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\741.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\751.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\761.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\771.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\781.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\791.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\80.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\801.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\81.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\811.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\821.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\831.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\841.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\851.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\861.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\90.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "Processing image: data\\91.png\n",
      "Resized image: (224, 224)\n",
      "Normalized image: (224, 224, 3)\n",
      "Converted to tensor: torch.Size([3, 224, 224])\n",
      "-------------------------------------------------------------Completed Preprocessing-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ImagePreprocessor('data', (224, 224), (0, 1))\n",
    "data, labels = preprocessor.preprocess_image()\n",
    "print(\"-------------------------------------------------------------Completed Preprocessing-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 131)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
